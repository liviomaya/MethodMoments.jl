<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>General GMM models · MethodMoments.jl</title><meta name="title" content="General GMM models · MethodMoments.jl"/><meta property="og:title" content="General GMM models · MethodMoments.jl"/><meta property="twitter:title" content="General GMM models · MethodMoments.jl"/><meta name="description" content="Documentation for MethodMoments.jl."/><meta property="og:description" content="Documentation for MethodMoments.jl."/><meta property="twitter:description" content="Documentation for MethodMoments.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">MethodMoments.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>General GMM models</a><ul class="internal"><li><a class="tocitem" href="#Minimal-example"><span>Minimal example</span></a></li><li><a class="tocitem" href="#The-GMM-setup"><span>The GMM setup</span></a></li><li><a class="tocitem" href="#Asymptotic-distributions"><span>Asymptotic distributions</span></a></li><li><a class="tocitem" href="#Defining-the-GMM-object"><span>Defining the GMM object</span></a></li><li><a class="tocitem" href="#Available-methods"><span>Available methods</span></a></li><li><a class="tocitem" href="#Long-run-variance"><span>Long-run variance</span></a></li><li><a class="tocitem" href="#Computing-the-Jacobian"><span>Computing the Jacobian</span></a></li><li><a class="tocitem" href="#Examples"><span>Examples</span></a></li></ul></li><li><a class="tocitem" href="../linear_regression/">Linear regressions</a></li><li><a class="tocitem" href="../api/">API</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>General GMM models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>General GMM models</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/liviomaya/MethodMoments.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/liviomaya/MethodMoments.jl/blob/main/docs/src/general_gmm.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="General-GMM-Models"><a class="docs-heading-anchor" href="#General-GMM-Models">General GMM Models</a><a id="General-GMM-Models-1"></a><a class="docs-heading-anchor-permalink" href="#General-GMM-Models" title="Permalink"></a></h1><p>The objective of this introduction is to quickly get you up and running with the package. For a comprehensive treatment of the generalized method of moments (GMM), see Hamilton (1994) or Hayashi (2000). For an introduction in the context of asset pricing, see Cochrane (2009).</p><h2 id="Minimal-example"><a class="docs-heading-anchor" href="#Minimal-example">Minimal example</a><a id="Minimal-example-1"></a><a class="docs-heading-anchor-permalink" href="#Minimal-example" title="Permalink"></a></h2><p>If you are familiar with GMM problems, you might prefer to grasp basic usage of the package through a simple example. Here, we estimate the shape parameter of an Exponential distribution using the moment conditions <span>$E[X - \theta] = 0$</span> and <span>$E[X^2 - 2 \theta^2] = 0$</span>. With a random sample, we define the moment function (dim 1: observations, dim 2: moments). </p><pre><code class="language-julia hljs">using MethodMoments
using Distributions, Optim
x = rand(Exponential(), 1000) # Exponential sample (θ = 1)
f(θ) = [(x .- θ[1]) (x .^ 2 .- 2 * θ[1]^2)]</code></pre><p>Start by building a <a href="../api/#MethodMoments.GMM"><code>GMM</code></a> object through the <a href="../api/#MethodMoments.gmm"><code>gmm</code></a> function. </p><pre><code class="language-julia hljs"># Define GMM object
weight = [1 0; 0 1]
θ_guess = [2.0]
G = gmm(f, θ_guess, weight)</code></pre><p>If you already computed the GMM estimate of <span>$\theta$</span> and passed it onto <code>gmm</code>, you can stop here. Otherwise:</p><pre><code class="language-julia hljs"># Solve GMM (exogenous weighting)
G = optimize(G)</code></pre><p>To solve the GMM problem again using a consistent estimate of the efficient weighting matrix:</p><pre><code class="language-julia hljs"># Solve GMM (optimal weighting)
G = vcov(G) # update long-run covariance matrix using first-stage estimates
GO = reoptimize(G)
summary(GO)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">
Method of Moments Estimates
 ------------- --------- --------- --------- --------- -----
                   θ        std        t      p(&gt;|t|)
 ------------- --------- --------- --------- --------- -----
  Parameter 1     1.014     0.031    32.656     0.000   ***
 ------------- --------- --------- --------- --------- -----
Significance: 1% (***) 2.5% (**) 5% (*) 10% (.)

Sample: 1000, Moments: 2 (1 overidentifying restriction)
Wald [θ = 0]: 1066.427 (p-val: 0.0 on 1 df)
Sargan-Hansen: 1.217 (p-val: 0.27 on 1 df)</code></pre><h2 id="The-GMM-setup"><a class="docs-heading-anchor" href="#The-GMM-setup">The GMM setup</a><a id="The-GMM-setup-1"></a><a class="docs-heading-anchor-permalink" href="#The-GMM-setup" title="Permalink"></a></h2><p>Let <span>$X_1, X_2, \dots, X_T$</span> be a sample of vector-valued random variables and <span>$\theta_0 \in \mathbb{R}^P$</span> the true yet unknown parameter vector. Given a function <span>$f(x, \theta) \in \mathbb{R}^M$</span>, with <span>$M \geq P$</span>,  the moment condition <span>$g(\theta_0) \equiv E[f(X, \theta_0)] = 0$</span> holds.</p><p>Fixing the sample, let <span>$\hat{g}(\theta) = \sum_{t=1}^T f(X_t, \theta) /T$</span> be the sample mean of <span>$f$</span>. Given a positive-definite weighting matrix <span>$\hat{W}$</span>, the basic GMM problem solves</p><p class="math-container">\[    \text{Min}_\theta \quad \hat{g}(\theta)&#39; \ \hat{W} \ \hat{g}(\theta). \qquad (1)\]</p><p>The GMM estimator <span>$\hat{\theta}$</span> is the parameter vector that solves (1). </p><h2 id="Asymptotic-distributions"><a class="docs-heading-anchor" href="#Asymptotic-distributions">Asymptotic distributions</a><a id="Asymptotic-distributions-1"></a><a class="docs-heading-anchor-permalink" href="#Asymptotic-distributions" title="Permalink"></a></h2><p>The following results of consistency and asymptotic distributions assume regularity conditions described in the references.</p><p>Let <span>$W = \hat{W}$</span> or its probability limit if <span>$\hat{W}$</span> is a function of the sample.</p><p>Let <span>$\hat{S}$</span> be a consistent estimator of <span>$S = \lim_{T \rightarrow \infty} T \ E \left[ \hat{g}(\theta_0) \hat{g}(\theta_0)&#39; \right]$</span>, the asymptotic covariance matrix of sample moments <span>$\hat{g}(\theta_0)$</span> (see <a href="#Long-run-variance">Long-run variance</a>).</p><p>Let <span>$\hat{D} = \partial \hat{g}(\hat{\theta})/\partial \theta&#39;$</span>, which consistently estimates the Jacobian <span>$D = \partial g(\theta_0)/\partial \theta&#39;$</span> (see <a href="#Computing-the-Jacobian">Computing the Jacobian</a>).</p><p><strong>Parameter Distribution</strong>: <span>$\hat{\theta} \overset{p}{\to} \theta_0$</span> and </p><p class="math-container">\[    \sqrt{T} (\hat{\theta} - \theta_0) \to \mathcal{N}(0, V_\theta) 
    \qquad \text{where} \qquad
    V_\theta = (D&#39; W D)^{-1} D&#39; W S W&#39; D (D&#39; W&#39; D)^{-1}\]</p><p>If <span>$W = S^{-1}$</span> is the optimal weighting matrix, then <span>$V_\theta = (D&#39; S^{-1} D)^{-1}$</span>. </p><p><strong>Moments Distribution</strong>: <span>$\hat{g}(\hat{\theta}) \overset{p}{\to} 0$</span> and </p><p class="math-container">\[    \sqrt{T} \hat{g}(\hat{\theta}) \to \mathcal{N}(0, V_g) 
    \qquad \text{where} \qquad
    V_g = (I - D (D&#39; W D)^{-1} D&#39; W) S (I - D (D&#39; W D)^{-1} D&#39; W)&#39;\]</p><p>If <span>$W = S^{-1}$</span> is the optimal weighting matrix, then <span>$V_g = S - D(D&#39; S^{-1}D)^{-1} D&#39;$</span>.</p><p>Note the difference between <span>$S$</span> and <span>$V_g$</span>: the former is the asymptotic variance of <span>$\hat{g}(\theta_0)$</span>; the latter is that of <span>$\hat{g}(\hat{\theta})$</span>. <span>$V_g$</span> is typically a singular matrix.</p><p>The Sargan-Hansen test for overidentified restrictions, or J test, uses the statistic <span>$\hat{J} = \hat{g}(\hat{\theta})&#39; \hat{W} \hat{g}(\hat{\theta})$</span>. If <span>$\hat{W} = \hat{S}^{-1}$</span>, then </p><p class="math-container">\[    T \ \hat{J} \rightarrow \chi^2 (M-P).\]</p><p><strong>Estimators</strong>: The (consistent) estimators <span>$\hat{V}_\theta$</span> of <span>$V_\theta$</span> and <span>$\hat{V}_g$</span> of <span>$V_g$</span> computed by MethodMoments.jl simply replace <span>$\hat{W}$</span>, <span>$\hat{D}$</span> and <span>$\hat{S}$</span> in the corresponding formulas.</p><h2 id="Defining-the-GMM-object"><a class="docs-heading-anchor" href="#Defining-the-GMM-object">Defining the GMM object</a><a id="Defining-the-GMM-object-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-the-GMM-object" title="Permalink"></a></h2><p>To start using the package, use the constructor function <a href="../api/#MethodMoments.gmm"><code>gmm</code></a>, which takes three arguments: the sample function <code>f</code> (<span>$f$</span>), a parameter vector <code>θ</code> (<span>$\theta$</span>), and a weighting matrix <code>W</code> (<span>$\hat{W}$</span>). </p><pre><code class="language-julia hljs">G = gmm(f, θ, W)</code></pre><ul><li><code>θ</code> should be a numerical <code>AbstractVector</code>, not a scalar. </li><li><code>f</code> must take a single argument. <code>f(θ)</code> must be a numerical <code>Matrix</code> or <code>Vector</code>, with observations in rows and moments in columns. </li><li><code>W</code> must be a square, positive-definite <code>AbstractMatrix</code>. If omitted, <code>W</code> = identity.</li></ul><p>The output of <a href="../api/#MethodMoments.gmm"><code>gmm</code></a> is an object of type <a href="../api/#MethodMoments.GMM"><code>GMM</code></a>, discussed below.</p><p>Note that <code>gmm</code> <strong>does not solve minimization problem (1)</strong> by itself. To perform a numerical optimization, use methods <code>optimize</code> and <code>reoptimize</code> <em>after</em> defining the <code>GMM</code> object.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>This version of MethodMoments.jl does not support lower and upper bounds for <span>$\theta$</span>. To impose such constraints, you can have <code>f</code> return a very large value. (But be careful: If <code>optimize</code> uses gradient or Hessian-based optimization algorithms, <code>f</code> should not return <code>Inf</code> or <code>-Inf</code>.) </p></div></div><p><a href="../api/#MethodMoments.GMM"><code>GMM</code></a> objects are not mutable. They store only the essential data related to the problem. Its fields are:</p><ul><li><code>func::Function</code>: sample function <span>$f$</span></li><li><code>params::Vector</code>: parameter vector <span>$\hat{\theta}$</span></li><li><code>weight::Matrix</code>: weighting matrix <span>$\hat{W}$</span></li><li><code>longcov::Matrix</code>: long-run covariance matrix <span>$\hat{S}$</span></li><li><code>twostep::Bool</code>: <code>true</code> if GMM problem was re-optimized with <span>$\hat{W} = \hat{S}^{-1}$</span></li><li><code>nobs::Int</code>: number of observations <span>$T$</span></li><li><code>nmom::Int</code>: number of moments <span>$M$</span></li><li><code>npar::Int</code>: number of parameters <span>$P$</span></li></ul><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>Function <code>summary</code> only displays the Sargan-Hansen test when <code>twostep = true</code>. The behavior of other functions is not affected by <code>twostep</code>.</p></div></div><h2 id="Available-methods"><a class="docs-heading-anchor" href="#Available-methods">Available methods</a><a id="Available-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Available-methods" title="Permalink"></a></h2><p>The methods below always take a <code>GMM</code> object <code>G</code> as argument, and use the data <span>$(f, \hat{\theta}, \hat{W}, \hat{S})$</span> stored in it. They never change <code>G</code> in place. See <a href="../api/">API documentation</a> for additional details.</p><ul><li><code>sample(G)</code>: compute sample of empirical moments <span>$f(\hat{\theta})$</span>.</li><li><code>moments(G)</code>: compute vector of empirical moments <span>$\hat{g}(\hat{\theta})$</span>.</li><li><code>vcov(G; lags=0)</code>: return new <code>GMM</code> object storing the Newey-West estimator of the long-run covariance matrix <span>$\hat{S}$</span>, with selected number of <code>lags</code> (see <a href="#Long-run-variance">Long-run variance</a>).</li><li><code>jacobian(G)</code>: compute the estimate <span>$\hat{D}$</span> of the Jacobian matrix (dim 1: moments, dim 2: parameters).</li><li><code>optimize(G; &lt;kwargs&gt;)</code>: return new <code>GMM</code> object storing the parameter vector that solves problem (1) with the weighting matrix stored in <code>G</code> (that is, <code>G.weight</code>). Long-run covariance matrix is <em>not</em> recalculated. See info box below. </li><li><code>reoptimize(G; &lt;kwargs&gt;)</code>: return new <code>GMM</code> object storing the parameter vector that solves problem (1) with the efficient weighting matrix <span>$S^{-1}$</span> (that is, <code>inv(G.longcov)</code>). Long-run covariance matrix is <em>not</em> recalculated. See info box below.</li><li><code>cov(G)</code>: compute asymptotic covariance matrix <span>$\hat{V}_\theta / T$</span> of <span>$\hat{\theta}$</span>.</li><li><code>var(G)</code>: compute element-by-element asymptotic variance of <span>$\hat{\theta}$</span>.</li><li><code>std(G)</code>: compute element-by-element asymptotic standard deviation of <span>$\hat{\theta}$</span>.</li><li><code>cor(G)</code>: compute asymptotic correlation matrix of <span>$\hat{\theta}$</span>.</li><li><code>momcov(G)</code>: compute asymptotic covariance matrix <span>$\hat{V}_g / T$</span> of <span>$\hat{\theta}$</span>.</li><li><code>summary(G)</code>: print summary of results.</li><li><code>wald(G; R, r, subset)</code>: print result of the Wald test on the null <span>$R \theta_{sub} = r$</span>, where <span>$\theta_{sub}$</span> is a subset of <span>$\theta$</span> corresponding to <code>θ[subset]</code>.</li></ul><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>Methods <code>optimize</code> and <code>reoptimize</code> perform numerical optimization of (1) using the <code>optimize</code> function of the <a href="https://julianlsolvers.github.io/Optim.jl/stable/"><code>Optim</code></a> package, passing over all keyword arguments (e.g. <code>method=Optim.BFGS()</code>) and using <code>G.params</code> as initial condition for the search.</p></div></div><h2 id="Long-run-variance"><a class="docs-heading-anchor" href="#Long-run-variance">Long-run variance</a><a id="Long-run-variance-1"></a><a class="docs-heading-anchor-permalink" href="#Long-run-variance" title="Permalink"></a></h2><p>The asymptotic covariance matrix of sample moments <span>$\hat{g}(\theta_0)$</span>, also known as long-run variance, is</p><p class="math-container">\[S 
= 
\lim_{T \rightarrow \infty} T \ E \left[ \hat{g}(\theta_0) \hat{g}(\theta_0)&#39; \right] 
= 
\sum_{i=-\infty}^\infty E \left[ f(X_t, \theta_0) \ f(X_{t-i}, \theta_0) \right].\]</p><p>The package estimates <span>$S$</span> through the heteroskedasticity and autocorrelation consistent (HAC) Newey-West estimator</p><p class="math-container">\[    \hat{S} = 
    \frac{1}{T} \sum_{t=1}^T \hat{f}_t&#39; \hat{f}_t
    +
    \frac{1}{T} \sum_{l=1}^k \sum_{t=l+1}^T w_{l} \left( \hat{f}_t&#39; \hat{f}_{t-l} + \hat{f}_{t-l}&#39; \hat{f}_t \right)\]</p><p>where <span>$w_l = 1 - l/(k+1)$</span>. Parameter <span>$k$</span> determines the number of terms with non-zero weight entering the second sum above. When <span>$k = 0$</span> (the default of function <code>vcov</code>), the statistic above reduces to the Huber-White estimator.</p><h2 id="Computing-the-Jacobian"><a class="docs-heading-anchor" href="#Computing-the-Jacobian">Computing the Jacobian</a><a id="Computing-the-Jacobian-1"></a><a class="docs-heading-anchor-permalink" href="#Computing-the-Jacobian" title="Permalink"></a></h2><p>The estimate <span>$\hat{D} = \partial \hat{g}(\hat{\theta})/\partial \theta&#39;$</span> of the Jacobian matrix is critical to compute the standard deviation of estimated parameters <span>$\hat{\theta}$</span> and empirical moments <span>$\hat{g}(\hat{\theta})$</span>. </p><p>Function <code>jacobian</code> uses a simple finite-differences algorithm to approximate <span>$\partial \hat{g}(\hat{\theta})/\partial \theta&#39;$</span>. In the direction of <span>$m$</span>-th component <span>$\theta_m$</span> of the parameter vector:</p><p class="math-container">\[    \frac{\partial \hat{g}(\theta)}{\partial \theta_m}
    = 
    \frac{\hat{g}(\theta_1,\dots, \theta_m+\epsilon,\dots,\theta_P) - \hat{g}(X, (\theta_1,\dots, \theta_m-\epsilon,\dots,\theta_P))}{2 \epsilon}.\]</p><p>with <span>$2 \epsilon = 1e-8$</span>. </p><h2 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h2><h3 id="Estimating-the-Mean"><a class="docs-heading-anchor" href="#Estimating-the-Mean">Estimating the Mean</a><a id="Estimating-the-Mean-1"></a><a class="docs-heading-anchor-permalink" href="#Estimating-the-Mean" title="Permalink"></a></h3><p>In this example, we estimate the mean <span>$\mu = 0$</span> of a Normal distribution. The moment condition is <span>$E[x - \mu] = 0$</span>.</p><pre><code class="language-julia hljs">using MethodMoments, Distributions

x = rand(Normal(), 10000) # Normal(0, 1) sample
f(μ) = x .- μ[1] # sample function

G = optimize(gmm(f, [2.0]));
summary(G)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">
Method of Moments Estimates
 ------------- --------- --------- --------- --------- ---
                   θ        std        t      p(&gt;|t|)
 ------------- --------- --------- --------- --------- ---
  Parameter 1     0.007     0.010     0.673     0.501
 ------------- --------- --------- --------- --------- ---
Significance: 1% (***) 2.5% (**) 5% (*) 10% (.)

Sample: 10000, Moments: 1 (no overidentifying restrictions)
Wald [θ = 0]: 0.453 (p-val: 0.501 on 1 df)</code></pre><p>If we knew beforehand the optimizing value <code>μ</code> of <span>$\mu$</span>, we could instead skip the optimization step, running only <code>G = gmm(f, [μ])</code>.</p><h3 id="Gamma-Distribution"><a class="docs-heading-anchor" href="#Gamma-Distribution">Gamma Distribution</a><a id="Gamma-Distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Gamma-Distribution" title="Permalink"></a></h3><p>We model the data as a sequence of realizations of a Gamma distribution, with shape parameter <span>$\alpha = 1$</span> and scale parameter <span>$\eta = 2$</span>. </p><pre><code class="language-julia hljs">using MethodMoments, Distributions, LinearAlgebra, Optim
x = rand(Gamma(1, 2), 1000) # sample</code></pre><p>We estimate the parameter vector <span>$\theta = (\alpha, \eta)$</span> by matching the first three moments of the Gamma distribution: </p><p class="math-container">\[    E[X - \mu] = 0 
    \qquad 
    E \left[ (X - \mu)^2 - \sigma^2 \right] = 0 
    \qquad 
    E \left[ \left( \frac{X - \mu}{\sigma} \right)^3 - \frac{2}{\sqrt{\alpha}} \right] = 0 \]</p><p>where <span>$\mu = \alpha \eta$</span> and <span>$\sigma = \sqrt{\alpha \eta^2}$</span>. These moments define function <code>f</code> in Julia.</p><pre><code class="language-julia hljs">function f(θ)
    α, η = θ

    # if outside valid range, return large moment error
    if (α &lt; 0) | (η &lt; 0)
        return 1e10 * ones(1000, 3)
    end

    μ = α * η
    σ = sqrt(α * η^2)

    M1 = x .- μ
    M2 = M1 .^ 2 .- σ^2
    M3 = (M1 ./ σ) .^ 3 .- (2 / sqrt(α))
    return [M1 M2 M3]
end</code></pre><p>The output of <code>f</code> gives the moment sample. </p><p>We can pre-specify the weighting matrix to focus on specific moments. For instance, we might be particularly interested in matching the sample variance:</p><pre><code class="language-julia hljs"># Exogenous weighting
guess = [5, 5]
weight = diagm([1, 5, 1])
G = optimize(gmm(f, guess, weight));</code></pre><p>We suspect that observations are serially correlated. To ensure consistency of our estimates of parameter variance, we change the estimate of the long-run covariance matrix using the Newey-West estimator, with three lags.  </p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; G = vcov(G, lags = 3);</code><code class="nohighlight hljs ansi" style="display:block;"></code><code class="nohighlight hljs ansi" style="display:block;"></code></pre><p>We are ready to check the results of the first-stage estimation.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; summary(G)</code><code class="nohighlight hljs ansi" style="display:block;">
Method of Moments Estimates
 ------------- --------- --------- --------- --------- -----
                   θ        std        t      p(&gt;|t|)
 ------------- --------- --------- --------- --------- -----
  Parameter 1     1.067     0.060    17.750     0.000   ***
  Parameter 2     1.973     0.125    15.833     0.000   ***
 ------------- --------- --------- --------- --------- -----
Significance: 1% (***) 2.5% (**) 5% (*) 10% (.)

Sample: 1000, Moments: 3 (1 overidentifying restriction)
Wald [θ = 0]: 2259.182 (p-val: 0.0 on 2 df)</code></pre><p>We can now solve the GMM problem a second time, using our Newey-West estimate of the long-run covariance matrix <span>$S^{-1}$</span> to compute the (feasible) optimal weighting matrix <span>$\hat{S}^{-1}$</span>.</p><pre><code class="language-julia hljs"># (Feasible) Optimal weighting
Go = reoptimize(G, method=Optim.Newton())</code></pre><p>The <code>GMM</code> object <code>Go</code> computed from the call to <code>reoptimize</code> does not change the stored estimate of the long-run variance matrix (<code>Go.longcov == G.longcov</code> returns <code>true</code>). </p><p>Since <code>Go.twostep == true</code>, printed <code>summary</code> now reports the Sargan-Hansen test.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; summary(Go)</code><code class="nohighlight hljs ansi" style="display:block;">
Method of Moments Estimates
 ------------- --------- --------- --------- --------- -----
                   θ        std        t      p(&gt;|t|)
 ------------- --------- --------- --------- --------- -----
  Parameter 1     1.041     0.060    17.262     0.000   ***
  Parameter 2     1.974     0.134    14.739     0.000   ***
 ------------- --------- --------- --------- --------- -----
Significance: 1% (***) 2.5% (**) 5% (*) 10% (.)

Sample: 1000, Moments: 3 (1 overidentifying restriction)
Wald [θ = 0]: 4777.462 (p-val: 0.0 on 2 df)
Sargan-Hansen: 0.855 (p-val: 0.355 on 1 df)</code></pre><p>Parameter estimates in <code>G</code> and <code>Go</code> differ because the optimal weighting matrix raises the penalty on first moment errors: </p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; diag(Go.weight) # Optimal weighting matrix</code><code class="nohighlight hljs ansi" style="display:block;">3-element Vector{Float64}:
 0.5135474747672533
 0.11111451782353465
 0.05686062603810833</code></pre><p>Indeed, the two-step solution better matches the sample mean: </p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; abs.([moments(G)[1] moments(Go)[1]]) # Go better matches first moment condition</code><code class="nohighlight hljs ansi" style="display:block;">1×2 Matrix{Float64}:
 0.0584494  0.00760016</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../linear_regression/">Linear regressions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Saturday 25 January 2025 22:01">Saturday 25 January 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
